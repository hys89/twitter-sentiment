{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b885dd147dac19bd0a33db3cd0da100bd5bc23"
   },
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4"
   },
   "outputs": [],
   "source": [
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "303e72966af732ddef0bd8108a321095314e44af"
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35e1a89dead5fd160e4c9a024a21d2e569fc89ff"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8b01a07df001e4abcc745900336c4db06e455f3"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "180f0dd2a95419e4602b5c0229822b0111c826f6"
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c3beecc618be68480b3d4f0de08d9d863da1dc1"
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563b3c44f1092dba0b853747b098e00509098cca"
   },
   "source": [
    "### Dataset details\n",
    "* **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* **ids**: The id of the tweet ( 2087)\n",
    "* **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* **user**: the user that tweeted (robotickilldozr)\n",
    "* **text**: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bba8f91cd70de4f5ea0fb0870ae2029b6e3dcc24"
   },
   "outputs": [],
   "source": [
    "dataset_filename = os.listdir(\"../input\")[0]\n",
    "dataset_path = os.path.join(\"..\",\"input\",dataset_filename)\n",
    "print(\"Open file:\", dataset_path)\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "936d499c00c4f1648bc16ca9d283c3b39be7fb10"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7486ed895b813c5246f97b31b6162b0f65ff763b"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9a7bb129e184967b13261fb5d253af451c75c5"
   },
   "source": [
    "### Map target label to String\n",
    "* **0** -> **NEGATIVE**\n",
    "* **2** -> **NEUTRAL**\n",
    "* **4** -> **POSITIVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14074b59106cb9550440839e48b832223fc9502f"
   },
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4449d473187f647a195a6ac6986b009da32a7f4b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19eb327803192f31cce3512aacb232f4d6b38715"
   },
   "outputs": [],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4329b1573518b03e497213efa7676220734ebb4b"
   },
   "source": [
    "### Pre-Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "649ebcb97969b9ac4301138783704bb3d7846a49"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f3e77ab9291d14687c49e71ba9b2b1e3323432"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5f9714a8507409bbe780eebf2855a33e8e6ba37"
   },
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f08a28aab2c3d16d8b9681a7d5d07587153a1cd6"
   },
   "source": [
    "### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2461bf564de1b4414841933d0c1d1bee5f5cc5a6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e19b9f25801ba86420decc266d2b3e6fb44f1ea"
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58d655af07653c594bec6bebcfb302a973b0ad9c"
   },
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72a5628ca81fd4b8983c12d93ae0bf950b86b6ae"
   },
   "outputs": [],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27cc2651c74227115d8bfd8c40e5618048e05edd"
   },
   "outputs": [],
   "source": [
    "w2v_model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e13563644468037258598637b49373ca96b9b879"
   },
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6852bc709a7cd20173cbeeb218505078f8f37c57"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45de439df3015030c71f84c2d170346936a1d68f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03b35903fc6260e190d6928d240ef7432de117fc"
   },
   "source": [
    "### Label Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33676e0efa39e97d89bd650b8b4eae933a22fbf0"
   },
   "outputs": [],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04239a9bef76e7922fd86098a5601dfde8ee4665"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04299c886911ca135583ab64878f213939a2990c"
   },
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f"
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233c0ea94055a03e2e7df3e2a13d036ec963484f"
   },
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ab488374b59e3f30f8b1ea92767d853c4846bac"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "833279d91e4286065968237fb5f2a0c2dd4d246c"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b299ef78f94c2085942c993a2d58753a7476305a"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e775ef4f1b74e6412457181383c39f2df554ef3f"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28d22eafd0c7d798dcf3d742bc92fb8577939e6c"
   },
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1331e08d590bb2aa2033706c8faca217afc0f1c3"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7733127cb8b380e0c807268903bf4d03ef92542"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a688df590386f5748da6fe00b01904fe6c71619e"
   },
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0873633dd49179c8cae17377641b97d323ef3b"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b659d390c6577dc5cdb6b6297934279b4e801d5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "267258196d96796ac69a7b8c466314bcf5d6ee42"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98ecd8f1b8b74594c3ea775dd68a094e92458022"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c72cd1e9d6c4fd799cbba7c813765ac4039dfc"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bdfc0f6a6af5bebc0271d83dd7432c91001409b"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0b0fa3d4b1bb14b3f5e3d169a369f3ebef29ae1"
   },
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed4086d651f2f8cbed11d3c909a8873607d29a06"
   },
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca38b1e6c9b5acfed7467de2cf02a78333108872"
   },
   "outputs": [],
   "source": [
    "predict(\"Yea we can't have medicine and water shortages and planes dropping out the sky like they said on the magic truth box.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e5fe647533be0148850de349fea6ef6f71303d1"
   },
   "outputs": [],
   "source": [
    "predict(\"Thank you EU. You calmness and rationality is embarrassing when compared to our lot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37064dffcc8920d34ccd54fac7c8b50e583a8269"
   },
   "outputs": [],
   "source": [
    "predict(\"Currently watching ‘Die Hard 2: Die Harder’. And my missus just said “why isn’t Die Hard 3 called ‘Die Even Harder-er”. And that’s why I love her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"EU agrees to Brexit deadline extension up to 31 January 2020, says Donald Tusk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ee72e47f84b6dbc32e02a783de5ec1661f157e1"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e920173eb05f04aecdd735bc5dff0f5be5f8d15"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_1d = []\n",
    "y_test_1d = list(df_test.target)\n",
    "scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3575191bb425ab871f3f41e83812ee84bb7e595"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a57dc6f6211c144491a70f533225edfa95a2dc66"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e23b957348dcc084249d3cc7538b972da471c2cd"
   },
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7fe05b7caa1c984ff1deb0be2f7c6bc043df9f5"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eb300f0c6693a618587c7dcf32f77f5416cbfb9"
   },
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cf76e6e09f8a60ed25947932b94c772eda44d23"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f014c32f3833db282e1a075c526604f34e3158c"
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b2b3ad5b592977b404acfa1c9ad303a62837255"
   },
   "outputs": [],
   "source": [
    "model.save(KERAS_MODEL)\n",
    "w2v_model.save(WORD2VEC_MODEL)\n",
    "pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
